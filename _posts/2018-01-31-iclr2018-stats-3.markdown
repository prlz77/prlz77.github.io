---
layout: post
title: An early overview of ICLR2018 (part 3)
date: 2018-01-31 00:00:00
description: An early overview of ICLR2018 (OpenReview). Part 3.
comments: true
categories:
- blog
permalink: iclr2018-stats-3/
---

Finally, decisions for the ICLR2018 conference are out! Congratulations to 
those who got their papers accepted, and I hope reviews serve as a source of
inspiration for those who got their papers rejected. 

Now that we have the acceptance decisions and author names have been disclosed, 
let's play with data to find interesting papers, who are the influential researchers, 
and which are the most significant organizations for the 2018 edition of this 
great conference :)

An analysis of the submission process can be found in 
[part 1](https://prlz77.github.io/iclr2018-stats/), and for the review process 
see [part 2](https://prlz77.github.io/iclr2018-stats-2/).

<!---->

ICLR 2018 is
growing fast. The program committee has officially stated that 935 conference 
submissions were presented, 505 more than last year (430 submissions on 2017). 
From these 935, 23 have been accepted for oral (2%), and 314 for poster (34%).

I have gathered the exact data which is summarized in the following plot:

<figure>
    <embed type="image/svg+xml" src='{{ "/assets/images/iclr2018/score_decision_histogram.svg" | absolute_url }}' />
</figure>
<br>
Not surprisingly, this year the top three  most frequent keywords have been *deep learning*, 
*reinforcement learning*, and *neural networks*, but which are the topics that
have been most successful this year?

<figure style="height:400px; overflow:scroll;">
    <embed type="image/svg+xml" src='{{ "/assets/images/iclr2018/keywords.svg" | absolute_url }}' />
</figure>
<br>
As it can be seen **meta-learning**, **exploration**, **model compression**,
**adversarial examples**, **variational inference** are the hottest topics this
year. For instance, 85% of the papers with the keyword *exploration* were accepted, 
while *classification* and *cnn* only show 12% acceptance rate. Curiously, submissions
with *Convolutional Neural Networks* have higher acceptance rates than with *cnn*s.


As for the submission scores, it is interesting to see there are submissions accepted as Poster
with a mean ~8 and an Oral submission with a mean score of ~6. To find these exact instances,
the following table with all the submissions can be used:


<link rel="stylesheet" type="text/css" href="https://cdn.datatables.net/v/dt/jq-3.2.1/dt-1.10.16/r-2.2.1/datatables.min.css"/>
 
<script type="text/javascript" src="https://cdn.datatables.net/v/dt/jq-3.2.1/dt-1.10.16/r-2.2.1/datatables.min.js"></script>
<script>
    $(document).ready(function() {
        $.getJSON('{{ "/assets/js/iclr2018/iclr2018.json" | absolute_url }}', function (table_data) {
            $('#iclr2018').DataTable({
                data: table_data,
                columns: [
                    {title: "Title", className: "dt-body-nowrap"},
                    {title: "Min score", className: "dt-center"},
                    {title: "Max Score", className: "dt-center"},
                    {title: "Mean Score", className: "dt-center"},
                    {title: "#MSGs", className: "dt-center"},
                    {title: "Last update", className: "dt-center"},
                    {title: "Decision", className: "dt-center"},
                ],
                "order": [[6, "asc"], [3, "desc"]]
            });
        });
    });
</script>

<table id="iclr2018" class="compact stripe order-column hover responsive" width="90%" cellspacing="0" style="font-size:0.875rem;"></table>
<br>

Browsing, I found that [Progressive Growing of GANs for Improved Quality, Stability, and Variation](https://openreview.net/forum?id=Hk99zCeAb) was accepted as Oral with a mean score of 5,67. 
The exact reviews were (8, **1**, and 8). However, the 1 was due to a concern with
the anonymization of the data. Finally, the decision was to overlook it
for the following reasons:

![]({{ "/assets/images/iclr2018/oral_decision.png" | absolute_url }})

In fact, most of the orals have one of their scores equal or greater than 8. The
only exception is [Beyond Word Importance: Contextual Decomposition to Extract Interactions from LSTMs](Beyond Word Importance: Contextual Decomposition to Extract Interactions from LSTMs), 
for which the review discussion lead to Reviewer3 to raise the score:

```
Explanations are convincing, I revise my rating.
- AnonReviewer3
```

Another borderline case is [Distributed Fine-tuning of Language Models on Private Data](Distributed Fine-tuning of Language Models on Private Data), which has been accepted as poster with a mean
score of 4,36 (4, 4, 5). In this case, reviewers were concerned about the 
simplicity and novelty of the paper, but the meta-reviewer found those concerns
not strong enough to trigger a rejection. More cases can be found where the acceptance
or rejection differs from the reviews, especially on the borderlines, for which
having an understanding meta-review can superimpose the reviews.

This makes one think about the influence of luck during the decision processes.
Is publishing a matter of statistics? We can make a plot of the submissions per 
author to see if publishing is a matter of quantity or quality:

<figure style="height:400px; overflow:scroll;">
    <embed type="image/svg+xml" src='{{ "/assets/images/iclr2018/authors.svg" | absolute_url }}' />
</figure>

It seems that, usually, the probability of acceptance is around 50%. However,
I beg the reviewer not to draw immediate conclusions because the reality is far more complex
and most of the authors in the graph are not always the first authors of the papers.
In fact, most of the first authors do not appear in the graph because lots of 
them only submitted one manuscript.

This also raises the question of which are the most prolific organizations:

<figure style="height:400px; overflow:scroll;">
    <embed type="image/svg+xml" src='{{ "/assets/images/iclr2018/affiliations.svg" | absolute_url }}' />
</figure>
<br>
Google [again](https://prlz77.github.io/iclr2017-stats/) ;) takes the lead, with 
their researchers appearing in 121 submissions (counted 97 last year)! This year
Carnegie Mellon has taken over Berkeley, and Microsoft has grown too. It is funny
to see organizations such as socher.org, referring to the e-mail of Richard Socher.

Although there exists competition between organizations, collaboration is key to
success. This is accounted in the following graph (best viewed on computer):

<div id="interactions" style="text-align:center;">
</div>

As it can be seen: Google, Microsoft, Carnegie Mellon, and Berkeley are the most 
connected organizations, this coincides as well with the number of submitted and
published papers.


This is the last post from the ICLR2018 overview series. I hope you enjoyed reading 
them as much as I have enjoyed writing and fiddling with the data. If you 
found any imprecision, do not hesitate to notify me.


<style>
.node {
  font: 300 11px "Helvetica Neue", Helvetica, Arial, sans-serif;
  fill: #bbb;
}

.node:hover {
  fill: #000;
}

.link {
  stroke: steelblue;
  stroke-opacity: 0.1;
  fill: none;
  pointer-events: none;
}

.node:hover,
.node--source,
.node--target {
  font-weight: 700;
}

.node--source {
  fill: #2ca02c;
}

.node--target {
  fill: #d62728;
}

.link--source,
.link--target {
  stroke-opacity: 1;
  stroke-width: 2px;
}

.link--source {
  stroke: #d62728;
}

.link--target {
  stroke: #d62728;
}

</style>

<script src="https://d3js.org/d3.v4.min.js"></script>
<script>

var diameter = 800,
    radius = diameter / 2,
    innerRadius = radius - 120;

var cluster = d3.cluster()
    .size([360, innerRadius]);

var line = d3.radialLine()
    .curve(d3.curveBundle.beta(0.85))
    .radius(function(d) { return d.y; })
    .angle(function(d) { return d.x / 180 * Math.PI; });

var svg = d3.select("#interactions").append("svg")
    .attr("width", diameter)
    .attr("height", diameter)
  .append("g")
    .attr("transform", "translate(" + radius + "," + radius + ")");

var link = svg.append("g").selectAll(".link"),
    node = svg.append("g").selectAll(".node");

d3.json('{{ "/assets/js/iclr2018/affiliation_links.json" | absolute_url }}', function(error, classes) {
  if (error) throw error;

  var root = packageHierarchy(classes)
      .sum(function(d) { return d.size; });

  cluster(root);

  link = link
    .data(packageImports(root.leaves()))
    .enter().append("path")
      .each(function(d) { d.source = d[0], d.target = d[d.length - 1]; })
      .attr("class", "link")
      .attr("d", line);

  node = node
    .data(root.leaves())
    .enter().append("text")
      .attr("class", "node")
      .attr("dy", "0.31em")
      .attr("transform", function(d) { return "rotate(" + (d.x - 90) + ")translate(" + (d.y + 8) + ",0)" + (d.x < 180 ? "" : "rotate(180)"); })
      .attr("text-anchor", function(d) { return d.x < 180 ? "start" : "end"; })
      .text(function(d) { return d.data.key; })
      .on("mouseover", mouseovered)
      .on("mouseout", mouseouted);
});

function mouseovered(d) {
  node
      .each(function(n) { n.target = n.source = false; });

  link
      .classed("link--target", function(l) { if (l.target === d) return l.source.source = true; })
      //.classed("link--source", function(l) { if (l.source === d) return l.target.target = true; })
    .filter(function(l) { return l.target === d || l.source === d; })
      .raise();

  node
      .classed("node--target", function(n) { return n.target; })
      //.classed("node--source", function(n) { return n.source; });
}

function mouseouted(d) {
  link
      .classed("link--target", false)
     // .classed("link--source", false);

  node
      .classed("node--target", false)
     // .classed("node--source", false);
}

// Lazily construct the package hierarchy from class names.
function packageHierarchy(classes) {
  var map = {};

  function find(name, data) {
    var node = map[name], i;
    if (!node) {
      node = map[name] = data || {name: name, children: []};
      if (name.length) {
        node.parent = find("");
        node.parent.children.push(node);
        node.key = name;
      }
    }
    return node;
  }

  classes.forEach(function(d) {
    find(d.name, d);
  });

  return d3.hierarchy(map[""]);
}

// Return a list of imports for the given array of nodes.
function packageImports(nodes) {
  var map = {},
      imports = [];

  // Compute a map from name to node.
  nodes.forEach(function(d) {
    map[d.data.name] = d;
  });

  // For each import, construct a link from the source to target node.
  nodes.forEach(function(d) {
    if (d.data.imports) d.data.imports.forEach(function(i) {
      imports.push(map[d.data.name].path(map[i]));
    });
  });

  return imports;
}
var new_w = $(window).width() / (800);
$("#interactions").css("zoom", new_w).css("width", $(window).width())

</script>


# Acknowledgements
Thanks to [@pepgonfaus](https://twitter.com/pepgonfaus) for reviewing and encouraging 
me to write this series of posts.

Go to part [1](https://prlz77.github.io/iclr2018-stats/), [2](https://prlz77.github.io/iclr2018-stats-2/)


